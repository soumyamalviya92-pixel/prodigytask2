
#  Task 02 - Image Generation with Pre-trained Models

### ðŸ“Œ Task Description
This task focuses on generating images from text prompts using **pre-trained generative models** such as **Stable Diffusion** or **DALLÂ·E Mini**.  
The objective is to understand how text-to-image models work and how to implement them using existing libraries without training a model from scratch.



### ðŸ› ï¸ Technologies Used
- Python  
- Google Colab  
- Hugging Face ðŸ¤— Transformers & Diffusers  
- Pre-trained Image Generation Models (Stable Diffusion)


## ðŸ“‚ Project Structure

### ðŸš€ How to Run the Project

1. Open **Google Colab**
2. Upload `prodigytask2.ipynb`  
   **OR** open it directly using the GitHub notebook URL
3. Run all cells sequentially
4. Enter a text prompt when asked
5. The generated image will be displayed as output

## ðŸ–¼ï¸ Output Information

âœ… **All generated images and outputs are displayed inside the Google Colab notebook**  
ðŸ“Œ File name: **`prodigytask2.ipynb`**

> GitHub does not always render heavy notebook outputs properly.  
> Therefore, **the notebook must be opened and executed in Google Colab to view the outputs clearly**.


### ðŸ§  Example Prompts Used

- *"A futuristic city at sunset"*  
- *"A robot reading a book in a library"*  
- *"An astronaut riding a horse on Mars"*


### ðŸ“Ž Notes

- No model training is required
- Only pre-trained models are used
- The notebook is kept clean and well-commented for easy understanding


### âœ… Internship Task Completion

This project successfully fulfills **Prodigy Internship â€“ Task 02** requirements by:
- Using pre-trained generative models
- Generating images from text prompts
- Displaying results in a reproducible Colab notebook

